# 第三阶段：上下文感知解码器设计

## 1. 目标

为了克服原始解码器在决策时仅关注局部节点特征的“短视”问题，我们设计一个能够感知全局图信息的上下文感知解码器。这将使模型在为每个变量计算 Q 值时，不仅能利用其自身特征，还能参考整个 SAT 问题的当前状态，从而做出更具前瞻性的决策。

## 2. 核心思想

核心思想是在解码阶段，将一个代表全局信息的“上下文向量”融入到每个变量节点的决策过程中。这个上下文向量将捕捉图中所有变量的综合状态。

## 3. 实现细节

相关逻辑将在 `gqsat/models.py` 文件中的 `EncoderCoreDecoder` 类中实现，主要改动其 `forward` 方法。

### 3.1. 计算全局上下文向量

在图神经网络核心（GNN Core）处理完所有节点后，我们会得到每个节点更新后的特征向量。

1.  **筛选变量节点**：我们首先从所有节点中，只筛选出代表“变量”的那些节点。
2.  **计算平均特征**：然后，我们对所有变量节点的特征向量沿着批次维度（batch dimension）求平均值，生成一个单一的、固定维度的全局上下文向量。
3.  **边界情况处理**：如果当前处理的图中不包含任何变量节点，`scatter_mean` 操作会产生 `NaN` 值。为了避免这种情况，我们将增加一个安全检查：如果不存在变量节点，则使用一个零向量作为该图的全局上下文。

### 3.2. 拼接特征向量

对于每一个需要计算 Q 值的变量节点，我们将其自身的特征向量与刚刚计算出的全局上下文向量进行拼接（concatenate）。

-   假设原始变量特征向量维度为 `D`。
-   全局上下文向量维度也为 `D`。
-   拼接后的增强特征向量维度将变为 `2 * D`。

### 3.3. 修改输出层

原有的输出线性层（`vertex_out_transform`）的输入维度是 `D`。为了适应拼接后的增强特征向量，我们需要将其输入维度修改为 `2 * D`。

这个修改后的线性层将接收增强特征向量，并最终为每个变量输出两个 Q 值（分别对应正、负两种极性）。
