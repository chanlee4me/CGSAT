# 第三阶段：基于冲突的奖励信号设计

## 1. 目标

设计一个与 SAT 求解器核心机制（CDCL，即冲突驱动的子句学习）更紧密耦合的密集奖励信号。该信号将基于决策后新产生的“冲突”数量，为强化学习智能体提供更即时、更具信息量的反馈，从而提高学习效率和求解性能。

## 2. 现有奖励机制的局限性

当前基于“问题是否解决”或“满足子句数”的奖励信号存在以下问题：

-   **奖励稀疏**：只有在最终解决问题或满足一个子句时才有反馈，智能体在中间步骤中无法判断其决策的优劣。
-   **与核心机制脱节**：无法反映 CDCL 求解器的内在逻辑。一个好的决策应该能有效剪枝搜索空间，快速导向或远离冲突，而现有奖励无法体现这一点。

## 3. 新奖励机制：基于冲突增量

### 核心思想

奖励的核心是**当前决策所导致的冲突数量的变化**。根据您的最新思路，一个高效的决策能够快速地探索问题结构，主动地、迅速地找到并暴露问题中的矛盾（即“冲突”），从而加速求解器的学习和剪枝过程。

-   一个好的决策应引导求解器**产生更多的冲突**，这表明该决策触及了问题的核心难点，因此**新产生的冲突越多，奖励应该越高**。
-   一个平庸的决策可能长时间无法引发冲突，表明它在搜索空间中“原地踏步”，因此应该获得较低或零奖励。

### 奖励计算公式

`奖励 = (决策后的总冲突数 - 决策前的总冲突数)`

我们直接使用冲突数的增量作为奖励。如果一个决策导致冲突数增加，它会获得正奖励；如果冲突数不变或减少，奖励为零或负，这是一个中性或负面的信号。

## 4. 实现路径（分步执行）

我们将严格按照以下步骤，在每一步都与您确认后再执行：

1.  **第一步：修改 C++ 头文件**
    -   **文件**：`minisat/minisat/gym/GymSolver.h`
    -   **操作**：在 `GymSolver` 类的 `public` 部分，声明一个新的成员函数 `int getNumConflicts();`。

2.  **第二步：修改 C++ 实现文件**
    -   **文件**：`minisat/minisat/gym/GymSolver.cc`
    -   **操作**：实现 `getNumConflicts()` 函数。该函数将直接返回底层 MiniSat 求解器实例（`solver`）的 `conflicts` 成员变量的值。

3.  **第三步：修改 SWIG 接口文件**
    -   **文件**：`minisat/minisat/gym/GymSolver.i`
    -   **操作**：在 `%include "GymSolver.h"` 之后，显式地将新函数 `int getNumConflicts();` 添加到接口中，以确保 SWIG 能正确地为它生成 Python 包装代码。

4.  **第四步：重新编译 C++ 扩展**
    -   **操作**：我们将运行编译脚本（例如 `make` 或 `python setup.py install`），将 C++ 的改动应用到 Python 环境中。

5.  **第五步：修改 Python 环境**
    -   **文件**：`minisat/minisat/gym/MiniSATEnv.py`
    -   **操作**：在 `step` 方法中，实现奖励计算逻辑：
        a. 在调用 `self.solver.step(action)` **之前**，通过 `self.solver.getNumConflicts()` 获取当前的冲突数并保存。
        b. 在调用 `step` **之后**，再次调用 `getNumConflicts()` 获取新的冲突数。
        c. 根据上述公式计算奖励值。
        d. 更新 `self.reward`。
